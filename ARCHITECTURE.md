# DentalCockpit Pro - Architecture Technique D√©taill√©e

**Version:** 2.0
**Date:** 12/11/2025
**Auteur:** Ismail Sialyen
**Powered by:** RCE (Relational Cognitive Engine)

---

## üìã Table des Mati√®res

1. [Vue d'Ensemble](#vue-densemble)
2. [Principes d'Architecture](#principes-darchitecture)
3. [Stack Technologique](#stack-technologique)
4. [Architecture Frontend](#architecture-frontend)
5. [Architecture Backend](#architecture-backend)
6. [Architecture RCE AI Engine](#architecture-rce-ai-engine)
7. [Architecture Base de Donn√©es](#architecture-base-de-donn√©es)
8. [Architecture Streaming & Temps R√©el](#architecture-streaming--temps-r√©el)
9. [Architecture Scalabilit√©](#architecture-scalabilit√©)
10. [S√©curit√© & Conformit√©](#s√©curit√©--conformit√©)
11. [Monitoring & Observabilit√©](#monitoring--observabilit√©)
12. [D√©ploiement & Infrastructure](#d√©ploiement--infrastructure)
13. [Plan de D√©veloppement](#plan-de-d√©veloppement)

---

## üèóÔ∏è Vue d'Ensemble

### Vision Architecturale

DentalCockpit Pro est une plateforme SaaS de gestion de cabinet dentaire aliment√©e par l'IA, con√ßue pour :
- **Haute Performance** : R√©activit√© < 100ms, streaming temps r√©el
- **Scalabilit√© Massive** : 10K+ utilisateurs concurrent
- **Disponibilit√©** : 99.9% uptime (SLA)
- **Intelligence Artificielle** : RCE orchestrant GPT-4, Claude, Gemini
- **Multi-tenant** : Isolation compl√®te par cabinet

### M√©triques Cibles

```
Performance:
‚îú‚îÄ API Response Time: < 100ms (p95)
‚îú‚îÄ Streaming Latency: < 50ms
‚îú‚îÄ Voice Transcription: < 2s (real-time)
‚îú‚îÄ AI Analysis: < 3s
‚îî‚îÄ Page Load: < 1.5s (FCP)

Scalabilit√©:
‚îú‚îÄ Concurrent Users: 10,000+
‚îú‚îÄ Requests/sec: 50,000+
‚îú‚îÄ AI Requests/sec: 1,000+
‚îú‚îÄ WebSocket Connections: 10,000+
‚îî‚îÄ Storage: Unlimited (S3)

Disponibilit√©:
‚îú‚îÄ Uptime: 99.9% (SLA)
‚îú‚îÄ RTO (Recovery Time): < 1h
‚îú‚îÄ RPO (Data Loss): < 5min
‚îî‚îÄ Backup Frequency: Real-time
```

---

## üéØ Principes d'Architecture

### 1. **Event-Driven Architecture (EDA)**
- Communication asynchrone via messages
- D√©couplage total des composants
- Scalabilit√© horizontale native

### 2. **Microservices Architecture**
- Services ind√©pendants et d√©ployables
- Responsabilit√© unique par service
- API Gateway centralis√©

### 3. **CQRS (Command Query Responsibility Segregation)**
- S√©paration lecture/√©criture
- Optimisation requ√™tes complexes
- Event Sourcing pour audit trail

### 4. **Reactive Programming**
- Streams de donn√©es (RxJS)
- Backpressure handling
- Non-blocking I/O partout

### 5. **Zero-Trust Security**
- Authentification √† chaque hop
- Encryption end-to-end
- Principe du moindre privil√®ge

---

## üõ†Ô∏è Stack Technologique

### Frontend

```typescript
Framework Principal:
‚îú‚îÄ Next.js 14+ (App Router, React Server Components)
‚îú‚îÄ TypeScript 5+ (strict mode)
‚îú‚îÄ React 18+ (Concurrent Features, Suspense)
‚îî‚îÄ Turborepo (monorepo management)

State Management:
‚îú‚îÄ Zustand (global state, lightweight)
‚îú‚îÄ TanStack Query v5 (server state, caching)
‚îú‚îÄ Jotai (atomic state)
‚îî‚îÄ RxJS 7+ (reactive streams)

UI & Styling:
‚îú‚îÄ Tailwind CSS 4+ (JIT, custom design system)
‚îú‚îÄ Radix UI (accessible primitives)
‚îú‚îÄ Framer Motion (animations)
‚îú‚îÄ Shadcn/ui (component library)
‚îî‚îÄ CSS Modules (scoped styles)

Real-time & Streaming:
‚îú‚îÄ Socket.io Client (WebSocket)
‚îú‚îÄ Server-Sent Events (SSE)
‚îú‚îÄ WebRTC (peer-to-peer video)
‚îî‚îÄ EventSource (streaming)

Data Visualization:
‚îú‚îÄ D3.js (dental charts, graphs)
‚îú‚îÄ Recharts (analytics dashboards)
‚îú‚îÄ Three.js (3D dental models)
‚îî‚îÄ Canvas API (drawing tools)

Voice & Media:
‚îú‚îÄ Web Audio API (voice recording)
‚îú‚îÄ MediaRecorder API (audio capture)
‚îú‚îÄ WebRTC (real-time communication)
‚îî‚îÄ Audio Worklet (processing)

Testing:
‚îú‚îÄ Vitest (unit tests)
‚îú‚îÄ Playwright (e2e tests)
‚îú‚îÄ Testing Library (component tests)
‚îî‚îÄ MSW (API mocking)
```

### Backend

```yaml
Runtime & Framework:
‚îú‚îÄ Node.js 20+ LTS (V8 engine)
‚îú‚îÄ Bun 1.0+ (performance critical services)
‚îú‚îÄ Fastify (HTTP framework, 2x faster than Express)
‚îú‚îÄ tRPC (type-safe API, end-to-end TypeScript)
‚îî‚îÄ GraphQL (Apollo Server v4)

API Layer:
‚îú‚îÄ REST API (Fastify + OpenAPI)
‚îú‚îÄ GraphQL (Apollo Federation)
‚îú‚îÄ gRPC (service-to-service)
‚îú‚îÄ WebSocket (Socket.io)
‚îî‚îÄ Server-Sent Events (streaming)

Message Queue & Streaming:
‚îú‚îÄ Apache Kafka (event streaming, main bus)
‚îú‚îÄ Redis Streams (real-time updates)
‚îú‚îÄ BullMQ (job queue, Redis-based)
‚îî‚îÄ RabbitMQ (task distribution, backup)

Background Jobs:
‚îú‚îÄ BullMQ (scheduled tasks)
‚îú‚îÄ Node-cron (periodic jobs)
‚îú‚îÄ Temporal.io (workflow orchestration)
‚îî‚îÄ Agenda (MongoDB-based jobs)

Validation & Security:
‚îú‚îÄ Zod (schema validation)
‚îú‚îÄ Helmet (security headers)
‚îú‚îÄ Rate-limiter-flexible (rate limiting)
‚îî‚îÄ bcrypt / Argon2 (password hashing)
```

### Databases

```yaml
Primary Database (NoSQL):
‚îú‚îÄ MongoDB 7+ (main data store)
‚îÇ   ‚îú‚îÄ Sharding enabled (horizontal scaling)
‚îÇ   ‚îú‚îÄ Replica Set (3+ nodes, high availability)
‚îÇ   ‚îú‚îÄ Change Streams (real-time sync)
‚îÇ   ‚îî‚îÄ Time Series Collections (metrics)

Vector Database:
‚îú‚îÄ Pinecone / Weaviate / Qdrant
‚îÇ   ‚îú‚îÄ Embeddings storage (1536 dimensions)
‚îÇ   ‚îú‚îÄ Semantic search (similar cases)
‚îÇ   ‚îú‚îÄ RAG (Retrieval Augmented Generation)
‚îÇ   ‚îî‚îÄ Medical knowledge base

Cache Layer:
‚îú‚îÄ Redis 7+ (primary cache)
‚îÇ   ‚îú‚îÄ Redis Cluster (distributed cache)
‚îÇ   ‚îú‚îÄ Redis Streams (event streaming)
‚îÇ   ‚îú‚îÄ Pub/Sub (real-time messaging)
‚îÇ   ‚îî‚îÄ RedisJSON (complex objects)
‚îÇ
‚îú‚îÄ KeyDB (Redis fork, multithreading)
‚îî‚îÄ Memcached (simple key-value)

Search Engine:
‚îú‚îÄ Elasticsearch 8+ / Meilisearch
‚îÇ   ‚îú‚îÄ Full-text search (patients, cases)
‚îÇ   ‚îú‚îÄ Aggregations (analytics)
‚îÇ   ‚îú‚îÄ Real-time indexing
‚îÇ   ‚îî‚îÄ Typo-tolerance

Time Series:
‚îú‚îÄ TimescaleDB (PostgreSQL extension)
‚îÇ   ‚îú‚îÄ Metrics storage
‚îÇ   ‚îú‚îÄ Patient vitals over time
‚îÇ   ‚îú‚îÄ System monitoring data
‚îÇ   ‚îî‚îÄ Automatic aggregation

Relational (Backup/Compliance):
‚îú‚îÄ PostgreSQL 16+ (audit logs, invoicing)
‚îÇ   ‚îú‚îÄ JSONB support
‚îÇ   ‚îú‚îÄ Row-level security
‚îÇ   ‚îú‚îÄ Logical replication
‚îÇ   ‚îî‚îÄ Point-in-time recovery
```

### RCE AI Engine

```yaml
Orchestration Layer:
‚îú‚îÄ Custom RCE Engine (Node.js/Python hybrid)
‚îÇ   ‚îú‚îÄ Model Router (intelligent selection)
‚îÇ   ‚îú‚îÄ Load Balancer (distributed requests)
‚îÇ   ‚îú‚îÄ Cache Layer (response caching)
‚îÇ   ‚îú‚îÄ Fallback Handler (failover logic)
‚îÇ   ‚îî‚îÄ Cost Optimizer (cheapest model selection)

AI Models Integration:
‚îú‚îÄ OpenAI GPT-4 Turbo / GPT-4o
‚îÇ   ‚îú‚îÄ API: REST (streaming)
‚îÇ   ‚îú‚îÄ Use: Text generation, transcription
‚îÇ   ‚îú‚îÄ Latency: ~1-2s
‚îÇ   ‚îî‚îÄ Cost: $0.01/1K tokens (input)
‚îÇ
‚îú‚îÄ Anthropic Claude 3.5 Sonnet
‚îÇ   ‚îú‚îÄ API: REST (streaming)
‚îÇ   ‚îú‚îÄ Use: Medical analysis, reasoning
‚îÇ   ‚îú‚îÄ Latency: ~1-2s
‚îÇ   ‚îî‚îÄ Cost: $0.003/1K tokens
‚îÇ
‚îú‚îÄ Google Gemini Pro 1.5
‚îÇ   ‚îú‚îÄ API: REST (streaming)
‚îÇ   ‚îú‚îÄ Use: Vision, multimodal analysis
‚îÇ   ‚îú‚îÄ Latency: ~1-2s
‚îÇ   ‚îî‚îÄ Cost: $0.002/1K tokens
‚îÇ
‚îî‚îÄ Whisper (OpenAI)
    ‚îú‚îÄ API: REST
    ‚îú‚îÄ Use: Voice transcription (real-time)
    ‚îú‚îÄ Latency: < 2s
    ‚îî‚îÄ Cost: $0.006/minute

Embeddings:
‚îú‚îÄ OpenAI text-embedding-3-large (1536 dim)
‚îú‚îÄ Cohere Embed v3
‚îî‚îÄ Local: Sentence-Transformers (fallback)

Fine-tuning:
‚îú‚îÄ GPT-4o Fine-tuning (dental terminology)
‚îú‚îÄ Domain-specific models (parodontology, orthodontics)
‚îî‚îÄ Custom embeddings (medical KB)

Vector Operations:
‚îú‚îÄ Pinecone / Weaviate (vector DB)
‚îú‚îÄ FAISS (local similarity search)
‚îî‚îÄ LangChain (RAG orchestration)
```

### Infrastructure & DevOps

```yaml
Cloud Provider:
‚îú‚îÄ AWS (primary)
‚îÇ   ‚îú‚îÄ ECS/EKS (container orchestration)
‚îÇ   ‚îú‚îÄ Lambda (serverless functions)
‚îÇ   ‚îú‚îÄ S3 (object storage)
‚îÇ   ‚îú‚îÄ CloudFront (CDN)
‚îÇ   ‚îú‚îÄ RDS (managed PostgreSQL)
‚îÇ   ‚îú‚îÄ ElastiCache (managed Redis)
‚îÇ   ‚îú‚îÄ DocumentDB (managed MongoDB)
‚îÇ   ‚îî‚îÄ SQS/SNS (messaging)
‚îÇ
‚îî‚îÄ Multi-cloud (disaster recovery)
    ‚îú‚îÄ Cloudflare (CDN, DDoS protection)
    ‚îî‚îÄ Vercel (frontend hosting)

Container Orchestration:
‚îú‚îÄ Kubernetes (K8s) 1.28+
‚îÇ   ‚îú‚îÄ EKS (AWS managed)
‚îÇ   ‚îú‚îÄ Horizontal Pod Autoscaler (HPA)
‚îÇ   ‚îú‚îÄ Vertical Pod Autoscaler (VPA)
‚îÇ   ‚îú‚îÄ Cluster Autoscaler
‚îÇ   ‚îî‚îÄ Karpenter (node provisioning)

Service Mesh:
‚îú‚îÄ Istio / Linkerd
‚îÇ   ‚îú‚îÄ Traffic management
‚îÇ   ‚îú‚îÄ Load balancing
‚îÇ   ‚îú‚îÄ Circuit breaking
‚îÇ   ‚îú‚îÄ mTLS (mutual TLS)
‚îÇ   ‚îî‚îÄ Observability

CI/CD:
‚îú‚îÄ GitHub Actions (primary)
‚îú‚îÄ ArgoCD (GitOps, K8s deployments)
‚îú‚îÄ Docker (containerization)
‚îî‚îÄ Terraform (Infrastructure as Code)

Monitoring & Observability:
‚îú‚îÄ Datadog / New Relic (APM)
‚îú‚îÄ Prometheus + Grafana (metrics)
‚îú‚îÄ Loki (logs aggregation)
‚îú‚îÄ Jaeger (distributed tracing)
‚îî‚îÄ Sentry (error tracking)

Security:
‚îú‚îÄ AWS WAF (Web Application Firewall)
‚îú‚îÄ AWS Shield (DDoS protection)
‚îú‚îÄ Cloudflare (CDN + security)
‚îú‚îÄ HashiCorp Vault (secrets management)
‚îî‚îÄ Snyk (vulnerability scanning)
```

---

## üé® Architecture Frontend

### Architecture Applicative

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    Browser Client                        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ   Pages    ‚îÇ  ‚îÇ  Components ‚îÇ  ‚îÇ   Hooks    ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  (Routes)  ‚îÇ  ‚îÇ  (Shared)   ‚îÇ  ‚îÇ  (Logic)   ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ        ‚îÇ               ‚îÇ                 ‚îÇ              ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ         State Management Layer               ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  (Zustand, TanStack Query, Jotai, RxJS)     ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ        ‚îÇ                                                 ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê       ‚îÇ
‚îÇ  ‚îÇ          API Communication Layer             ‚îÇ       ‚îÇ
‚îÇ  ‚îÇ  (tRPC, GraphQL, WebSocket, SSE)            ‚îÇ       ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò       ‚îÇ
‚îÇ        ‚îÇ                                                 ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚ñº
   [ API Gateway ]
```

### Modules Frontend

```typescript
/apps
  /web-app                    # Main Next.js application
    /app
      /(auth)                # Auth routes (login, register)
      /(dashboard)           # Dashboard routes (protected)
        /patients            # Patient management
        /dental-chart        # Dental charting
        /paro                # Periodontology
        /ortho               # Orthodontics
        /prescriptions       # Prescriptions
        /imaging             # Medical imaging
        /ai                  # AI features
        /admin               # Administration
      /api                   # API routes (Next.js API)
    /components
      /ui                    # Base UI components (Shadcn)
      /features              # Feature-specific components
      /layouts               # Layout components
    /lib
      /api                   # API clients (tRPC, GraphQL)
      /hooks                 # Custom React hooks
      /utils                 # Utility functions
      /stores                # Zustand stores
    /styles
      /globals.css           # Global styles
      /themes                # Theme configuration

  /landing-page              # Marketing site (separate app)
    /[locale]                # i18n routes (fr, nl, en, de)

/packages
  /ui                        # Shared UI components
  /config                    # Shared configs
  /tsconfig                  # TypeScript configs
  /eslint-config             # ESLint configs
```

### State Management Strategy

```typescript
// 1. Server State (TanStack Query)
// - API data, caching, refetching
import { useQuery, useMutation } from '@tanstack/react-query'

const usePatients = () => {
  return useQuery({
    queryKey: ['patients'],
    queryFn: fetchPatients,
    staleTime: 5 * 60 * 1000, // 5 min
  })
}

// 2. Global Client State (Zustand)
// - User preferences, UI state
import { create } from 'zustand'

const useAppStore = create((set) => ({
  theme: 'dark',
  sidebarOpen: true,
  toggleSidebar: () => set((s) => ({ sidebarOpen: !s.sidebarOpen }))
}))

// 3. Atomic State (Jotai)
// - Granular, composable state
import { atom, useAtom } from 'jotai'

const selectedToothAtom = atom<number | null>(null)

// 4. Reactive Streams (RxJS)
// - Real-time updates, complex async flows
import { fromEvent } from 'rxjs'
import { debounceTime, switchMap } from 'rxjs/operators'

const search$ = fromEvent(input, 'input').pipe(
  debounceTime(300),
  switchMap(e => searchPatients(e.target.value))
)
```

### Real-time Communication

```typescript
// WebSocket Connection (Socket.io)
import io from 'socket.io-client'

const socket = io('wss://api.dentalcockpit.pro', {
  auth: { token: 'jwt-token' },
  transports: ['websocket'],
  reconnection: true,
  reconnectionDelay: 1000,
  reconnectionAttempts: 5
})

// Subscribe to real-time events
socket.on('patient:updated', (data) => {
  queryClient.invalidateQueries(['patients', data.id])
})

socket.on('ai:transcription', (chunk) => {
  setTranscription(prev => prev + chunk.text)
})

// Server-Sent Events (SSE) for streaming
const eventSource = new EventSource('/api/ai/stream')

eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data)
  setStreamData(prev => [...prev, data])
}
```

### Performance Optimizations

```typescript
// 1. Code Splitting (Dynamic Imports)
const DentalChart = dynamic(() => import('@/components/DentalChart'), {
  loading: () => <Skeleton />,
  ssr: false
})

// 2. Image Optimization (Next.js Image)
import Image from 'next/image'

<Image
  src="/xray.jpg"
  alt="X-ray"
  width={800}
  height={600}
  loading="lazy"
  placeholder="blur"
/>

// 3. React Server Components
// app/patients/page.tsx
async function PatientsPage() {
  const patients = await fetchPatients() // Server-side
  return <PatientList patients={patients} />
}

// 4. Suspense Boundaries
<Suspense fallback={<Loading />}>
  <PatientDetails id={id} />
</Suspense>

// 5. Virtual Scrolling (react-window)
import { FixedSizeList } from 'react-window'

<FixedSizeList
  height={600}
  itemCount={1000}
  itemSize={50}
  width="100%"
>
  {Row}
</FixedSizeList>
```

---

## ‚öôÔ∏è Architecture Backend

### Microservices Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                      API Gateway                             ‚îÇ
‚îÇ              (Kong / AWS API Gateway)                        ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê                  ‚îÇ
‚îÇ  ‚îÇ   Auth   ‚îÇ  ‚îÇ   Rate   ‚îÇ  ‚îÇ  Load    ‚îÇ                  ‚îÇ
‚îÇ  ‚îÇ          ‚îÇ  ‚îÇ  Limit   ‚îÇ  ‚îÇ Balance  ‚îÇ                  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚îÇ               ‚îÇ               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Patient    ‚îÇ ‚îÇ   Imaging   ‚îÇ ‚îÇ     AI     ‚îÇ
‚îÇ   Service    ‚îÇ ‚îÇ   Service   ‚îÇ ‚îÇ  Service   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ               ‚îÇ               ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Prescription‚îÇ ‚îÇ   Billing   ‚îÇ ‚îÇ  Analytics ‚îÇ
‚îÇ   Service    ‚îÇ ‚îÇ   Service   ‚îÇ ‚îÇ  Service   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚îÇ               ‚îÇ               ‚îÇ
        ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                        ‚îÇ
                ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                ‚îÇ  Event Bus     ‚îÇ
                ‚îÇ   (Kafka)      ‚îÇ
                ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Core Services

#### 1. **Patient Service**

```typescript
Responsabilit√©s:
‚îú‚îÄ CRUD patients
‚îú‚îÄ Timeline patient
‚îú‚îÄ Documents m√©dicaux
‚îú‚îÄ Rendez-vous
‚îî‚îÄ Historique modifications

Technologies:
‚îú‚îÄ Fastify + tRPC
‚îú‚îÄ MongoDB (patient data)
‚îú‚îÄ Redis (cache)
‚îú‚îÄ Kafka (events)
‚îî‚îÄ Elasticsearch (search)

Endpoints:
‚îú‚îÄ GET    /patients
‚îú‚îÄ POST   /patients
‚îú‚îÄ GET    /patients/:id
‚îú‚îÄ PATCH  /patients/:id
‚îú‚îÄ DELETE /patients/:id
‚îú‚îÄ GET    /patients/:id/timeline
‚îî‚îÄ WS     /patients/:id/live

√âv√©nements √âmis:
‚îú‚îÄ patient.created
‚îú‚îÄ patient.updated
‚îú‚îÄ patient.deleted
‚îî‚îÄ patient.visit_started
```

#### 2. **AI Service (RCE Engine)**

```typescript
Responsabilit√©s:
‚îú‚îÄ Orchestration mod√®les IA
‚îú‚îÄ Transcription vocale (Whisper)
‚îú‚îÄ G√©n√©ration anamn√®se (GPT-4)
‚îú‚îÄ Analyse images (Gemini)
‚îú‚îÄ Diagnostic assistant (Claude)
‚îî‚îÄ Semantic search (embeddings)

Technologies:
‚îú‚îÄ Fastify + GraphQL
‚îú‚îÄ Python (ML tasks)
‚îú‚îÄ Redis (queue + cache)
‚îú‚îÄ Kafka (streaming)
‚îú‚îÄ Pinecone (vector DB)
‚îú‚îÄ LangChain (RAG)
‚îî‚îÄ OpenAI/Anthropic/Google APIs

Endpoints:
‚îú‚îÄ POST   /ai/transcribe (streaming)
‚îú‚îÄ POST   /ai/anamnesis
‚îú‚îÄ POST   /ai/analyze-image
‚îú‚îÄ POST   /ai/diagnose
‚îú‚îÄ POST   /ai/search-similar
‚îú‚îÄ WS     /ai/stream
‚îî‚îÄ SSE    /ai/transcribe/stream

Model Router Logic:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Request Input   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Analyzer ‚îÇ (task type, urgency, cost)
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Model Selection     ‚îÇ
    ‚îÇ  ‚îú‚îÄ Transcription ‚Üí Whisper
    ‚îÇ  ‚îú‚îÄ Text Gen ‚Üí GPT-4 / Claude
    ‚îÇ  ‚îú‚îÄ Vision ‚Üí Gemini
    ‚îÇ  ‚îî‚îÄ Cheap ‚Üí GPT-3.5
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Load Balancer   ‚îÇ (rate limits, quotas)
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ   API Call       ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Cache Result    ‚îÇ (Redis, 1h TTL)
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ  Return Result   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 3. **Imaging Service**

```typescript
Responsabilit√©s:
‚îú‚îÄ Upload images (X-ray, 3D scans, photos)
‚îú‚îÄ Image processing (resize, compress)
‚îú‚îÄ DICOM handling
‚îú‚îÄ AI analysis trigger
‚îî‚îÄ Annotations & measurements

Technologies:
‚îú‚îÄ Fastify
‚îú‚îÄ Sharp (image processing)
‚îú‚îÄ DICOM parser
‚îú‚îÄ S3 (storage)
‚îú‚îÄ CloudFront (CDN)
‚îú‚îÄ Redis (metadata cache)
‚îî‚îÄ Kafka (events)

Storage Strategy:
‚îú‚îÄ Original: S3 Standard (hot)
‚îú‚îÄ Processed: S3 Standard (hot)
‚îú‚îÄ Archive: S3 Glacier (cold, >1 year)
‚îî‚îÄ CDN: CloudFront (edge locations)

Endpoints:
‚îú‚îÄ POST   /imaging/upload
‚îú‚îÄ GET    /imaging/:id
‚îú‚îÄ POST   /imaging/:id/analyze
‚îú‚îÄ POST   /imaging/:id/annotate
‚îú‚îÄ GET    /imaging/:id/thumbnail
‚îî‚îÄ DELETE /imaging/:id
```

#### 4. **Prescription Service**

```typescript
Responsabilit√©s:
‚îú‚îÄ Cr√©ation prescriptions
‚îú‚îÄ Int√©gration Recip-e (Belgique)
‚îú‚îÄ V√©rification interactions m√©dicamenteuses
‚îú‚îÄ Base m√©dicamenteuse
‚îú‚îÄ Historique prescriptions
‚îî‚îÄ Signatures √©lectroniques

Technologies:
‚îú‚îÄ Fastify + tRPC
‚îú‚îÄ PostgreSQL (prescriptions, audit)
‚îú‚îÄ MongoDB (m√©dicaments DB)
‚îú‚îÄ Redis (cache DB m√©dicaments)
‚îú‚îÄ Recip-e API (e-Health Belgium)
‚îî‚îÄ Kafka (events)

Workflow:
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Create Rx        ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Check Interactions   ‚îÇ (drug database)
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ AI Suggestions       ‚îÇ (RCE + patient history)
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Generate Recip-e     ‚îÇ (QR code, e-Health)
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Digital Signature    ‚îÇ (eID, PKCS#11)
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Send to Patient      ‚îÇ (Email/SMS)
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

#### 5. **Billing Service**

```typescript
Responsabilit√©s:
‚îú‚îÄ Facturation patients
‚îú‚îÄ Int√©gration INAMI
‚îú‚îÄ Gestion mutuelles
‚îú‚îÄ Attestations √©lectroniques
‚îú‚îÄ Paiements (Stripe, Mollie)
‚îî‚îÄ Rapports comptables

Technologies:
‚îú‚îÄ Fastify + tRPC
‚îú‚îÄ PostgreSQL (invoices, transactions)
‚îú‚îÄ Stripe API (payments)
‚îú‚îÄ INAMI API (Belgian healthcare)
‚îú‚îÄ Redis (cache rates)
‚îú‚îÄ Kafka (events)
‚îî‚îÄ PDF generation (Puppeteer)

Endpoints:
‚îú‚îÄ POST   /billing/invoice
‚îú‚îÄ POST   /billing/inami/attestation
‚îú‚îÄ GET    /billing/invoices
‚îú‚îÄ POST   /billing/payment
‚îú‚îÄ GET    /billing/reports
‚îî‚îÄ POST   /billing/export
```

#### 6. **Analytics Service**

```typescript
Responsabilit√©s:
‚îú‚îÄ KPIs temps r√©el
‚îú‚îÄ Pr√©visions IA (revenus, taux remplissage)
‚îú‚îÄ Rapports personnalis√©s
‚îú‚îÄ Data warehouse
‚îî‚îÄ Business Intelligence

Technologies:
‚îú‚îÄ Node.js + GraphQL
‚îú‚îÄ TimescaleDB (time-series)
‚îú‚îÄ ClickHouse (analytics DB)
‚îú‚îÄ Apache Superset (BI)
‚îú‚îÄ Python (ML predictions)
‚îú‚îÄ Redis (cache)
‚îî‚îÄ Kafka (streaming analytics)

M√©triques Track√©es:
‚îú‚îÄ Patients actifs
‚îú‚îÄ Taux remplissage agenda
‚îú‚îÄ Revenus (jour/semaine/mois)
‚îú‚îÄ No-shows rate
‚îú‚îÄ Analyses IA utilis√©es
‚îú‚îÄ Temps moyen consultation
‚îî‚îÄ Satisfaction patient (NPS)
```

---

## üß† Architecture RCE AI Engine

### RCE Orchestration Layer

```python
# rce_engine/orchestrator.py

from dataclasses import dataclass
from enum import Enum
from typing import Optional, List

class ModelProvider(Enum):
    OPENAI = "openai"
    ANTHROPIC = "anthropic"
    GOOGLE = "google"

class TaskType(Enum):
    TRANSCRIPTION = "transcription"
    TEXT_GENERATION = "text_generation"
    IMAGE_ANALYSIS = "image_analysis"
    DIAGNOSIS = "diagnosis"
    SEMANTIC_SEARCH = "semantic_search"

@dataclass
class ModelCapability:
    provider: ModelProvider
    model_name: str
    task_types: List[TaskType]
    cost_per_1k: float
    latency_ms: int
    quality_score: float
    max_tokens: int

class RCEOrchestrator:
    """
    RCE (Relational Cognitive Engine) Orchestrator
    Intelligently routes requests to optimal AI model
    """

    def __init__(self):
        self.models = self._init_models()
        self.cache = RedisCache()
        self.rate_limiter = RateLimiter()
        self.load_balancer = LoadBalancer()

    def _init_models(self) -> List[ModelCapability]:
        return [
            # OpenAI Models
            ModelCapability(
                provider=ModelProvider.OPENAI,
                model_name="gpt-4-turbo",
                task_types=[TaskType.TEXT_GENERATION, TaskType.DIAGNOSIS],
                cost_per_1k=0.01,
                latency_ms=1500,
                quality_score=0.95,
                max_tokens=128000
            ),
            ModelCapability(
                provider=ModelProvider.OPENAI,
                model_name="whisper-1",
                task_types=[TaskType.TRANSCRIPTION],
                cost_per_1k=0.006,
                latency_ms=2000,
                quality_score=0.98,
                max_tokens=None
            ),

            # Anthropic Models
            ModelCapability(
                provider=ModelProvider.ANTHROPIC,
                model_name="claude-3-5-sonnet",
                task_types=[TaskType.TEXT_GENERATION, TaskType.DIAGNOSIS],
                cost_per_1k=0.003,
                latency_ms=1200,
                quality_score=0.97,
                max_tokens=200000
            ),

            # Google Models
            ModelCapability(
                provider=ModelProvider.GOOGLE,
                model_name="gemini-pro-1.5",
                task_types=[TaskType.IMAGE_ANALYSIS, TaskType.TEXT_GENERATION],
                cost_per_1k=0.002,
                latency_ms=1000,
                quality_score=0.92,
                max_tokens=1000000
            ),
        ]

    async def route_request(
        self,
        task_type: TaskType,
        input_data: dict,
        priority: str = "balanced",  # "cost", "speed", "quality", "balanced"
        user_id: str = None
    ) -> dict:
        """
        Intelligently route request to optimal model
        """

        # 1. Check cache
        cache_key = self._generate_cache_key(task_type, input_data)
        cached = await self.cache.get(cache_key)
        if cached:
            return {"source": "cache", "result": cached}

        # 2. Select optimal model
        model = self._select_model(task_type, priority, user_id)

        # 3. Check rate limits
        if not await self.rate_limiter.check(user_id, model.provider):
            # Fallback to cheaper model
            model = self._select_fallback_model(task_type)

        # 4. Execute request with load balancing
        try:
            result = await self.load_balancer.execute(
                model=model,
                input_data=input_data
            )

            # 5. Cache result
            await self.cache.set(cache_key, result, ttl=3600)

            # 6. Log metrics
            await self._log_metrics(model, result)

            return {
                "source": "ai",
                "model": model.model_name,
                "provider": model.provider.value,
                "result": result
            }

        except Exception as e:
            # Fallback chain
            return await self._execute_fallback(task_type, input_data)

    def _select_model(
        self,
        task_type: TaskType,
        priority: str,
        user_id: str
    ) -> ModelCapability:
        """
        Select optimal model based on task and priority
        """
        candidates = [m for m in self.models if task_type in m.task_types]

        if priority == "cost":
            return min(candidates, key=lambda m: m.cost_per_1k)
        elif priority == "speed":
            return min(candidates, key=lambda m: m.latency_ms)
        elif priority == "quality":
            return max(candidates, key=lambda m: m.quality_score)
        else:  # balanced
            # Weighted score
            return max(candidates, key=lambda m: (
                m.quality_score * 0.5 +
                (1 - m.cost_per_1k / 0.01) * 0.3 +
                (1 - m.latency_ms / 3000) * 0.2
            ))

    async def stream_response(
        self,
        task_type: TaskType,
        input_data: dict,
        callback: callable
    ):
        """
        Stream responses in real-time (for transcription, text generation)
        """
        model = self._select_model(task_type, "speed", None)

        async for chunk in self._stream_from_model(model, input_data):
            await callback(chunk)
```

### Streaming Architecture

```typescript
// Real-time AI Transcription Streaming

// Backend: ai-service/streaming.ts
import { EventEmitter } from 'events'

class TranscriptionStream extends EventEmitter {
  private whisperClient: WhisperClient
  private buffer: Buffer[] = []

  async startStream(audioStream: ReadableStream) {
    const reader = audioStream.getReader()

    while (true) {
      const { done, value } = await reader.read()
      if (done) break

      this.buffer.push(value)

      // Send chunks every 500ms for real-time transcription
      if (this.buffer.length >= 10) {
        const chunk = Buffer.concat(this.buffer)
        this.buffer = []

        const transcription = await this.whisperClient.transcribe(chunk)

        // Emit to all connected clients via Kafka
        await kafka.send({
          topic: 'transcription-stream',
          messages: [{
            key: sessionId,
            value: JSON.stringify({
              text: transcription.text,
              timestamp: Date.now(),
              confidence: transcription.confidence
            })
          }]
        })
      }
    }
  }
}

// Frontend: hooks/useAITranscription.ts
import { useEffect, useState } from 'react'

export const useAITranscription = (sessionId: string) => {
  const [transcription, setTranscription] = useState('')
  const [isRecording, setIsRecording] = useState(false)

  useEffect(() => {
    const eventSource = new EventSource(
      `/api/ai/transcribe/stream?session=${sessionId}`
    )

    eventSource.onmessage = (event) => {
      const data = JSON.parse(event.data)
      setTranscription(prev => prev + ' ' + data.text)
    }

    return () => eventSource.close()
  }, [sessionId])

  const startRecording = async () => {
    const stream = await navigator.mediaDevices.getUserMedia({ audio: true })
    const mediaRecorder = new MediaRecorder(stream)

    mediaRecorder.ondataavailable = async (event) => {
      // Send audio chunk to backend
      await fetch('/api/ai/transcribe/chunk', {
        method: 'POST',
        body: event.data
      })
    }

    mediaRecorder.start(500) // chunk every 500ms
    setIsRecording(true)
  }

  return { transcription, isRecording, startRecording }
}
```

---

## üíæ Architecture Base de Donn√©es

### Data Model (MongoDB)

```typescript
// Patient Collection
{
  _id: ObjectId,
  tenantId: ObjectId,  // Multi-tenant isolation
  personalInfo: {
    firstName: string,
    lastName: string,
    dateOfBirth: Date,
    gender: "M" | "F" | "X",
    nationalRegister: string,  // Encrypted
    email: string,
    phone: string,
    address: {
      street: string,
      city: string,
      postalCode: string,
      country: string
    }
  },
  medicalInfo: {
    allergies: string[],
    medications: string[],
    conditions: string[],
    bloodType: string,
    insuranceNumber: string  // Encrypted
  },
  dentalHistory: {
    lastVisit: Date,
    nextAppointment: Date,
    treatments: [{
      date: Date,
      toothNumber: number,
      treatmentType: string,
      notes: string,
      cost: number
    }],
    currentStatus: {
      teeth: {
        [toothNumber: number]: {
          status: "healthy" | "caries" | "filled" | "crown" | "missing",
          lastUpdated: Date,
          notes: string
        }
      }
    }
  },
  timeline: [{
    _id: ObjectId,
    timestamp: Date,
    type: "visit" | "treatment" | "note" | "image" | "prescription",
    data: object,
    createdBy: ObjectId
  }],
  aiData: {
    embeddings: number[],  // 1536 dimensions
    riskScores: {
      caries: number,
      periodontal: number,
      orthodontic: number
    },
    predictions: object
  },
  metadata: {
    createdAt: Date,
    updatedAt: Date,
    createdBy: ObjectId,
    lastModifiedBy: ObjectId,
    version: number  // Optimistic locking
  }
}

// Indexes
db.patients.createIndex({ tenantId: 1, "personalInfo.lastName": 1 })
db.patients.createIndex({ tenantId: 1, "personalInfo.email": 1 }, { unique: true })
db.patients.createIndex({ "timeline.timestamp": -1 })
db.patients.createIndex({ "dentalHistory.nextAppointment": 1 })

// Sharding Key
sh.shardCollection("dentalcockpit.patients", { tenantId: 1, _id: 1 })
```

```typescript
// Medical Images Collection
{
  _id: ObjectId,
  tenantId: ObjectId,
  patientId: ObjectId,
  type: "xray" | "scan3d" | "photo" | "camera",
  s3Key: string,  // S3 object key
  s3Bucket: string,
  cdnUrl: string,  // CloudFront URL
  metadata: {
    width: number,
    height: number,
    size: number,
    mimeType: string,
    captureDate: Date,
    device: string,
    dicomData: object  // If DICOM
  },
  aiAnalysis: {
    analyzed: boolean,
    analysisDate: Date,
    model: string,
    results: {
      detections: [{
        type: "caries" | "bone-loss" | "crown" | "filling",
        confidence: number,
        boundingBox: { x, y, width, height },
        toothNumber: number
      }],
      recommendations: string[],
      riskScore: number
    }
  },
  annotations: [{
    userId: ObjectId,
    timestamp: Date,
    type: "measurement" | "note" | "marker",
    data: object
  }],
  createdAt: Date,
  updatedAt: Date
}

// Indexes
db.medicalImages.createIndex({ tenantId: 1, patientId: 1, createdAt: -1 })
db.medicalImages.createIndex({ "aiAnalysis.analyzed": 1 })
```

### Vector Database (Pinecone)

```python
# Semantic Search & RAG

# Store patient case embeddings
{
  "id": "case_123456",
  "values": [0.1, 0.2, ...],  # 1536 dimensions
  "metadata": {
    "tenantId": "tenant_abc",
    "patientId": "patient_xyz",
    "diagnosis": "Severe periodontitis",
    "treatment": "Scaling and root planing",
    "outcome": "Successful",
    "date": "2025-01-15",
    "symptoms": ["bleeding gums", "tooth mobility"],
    "age": 45,
    "gender": "F"
  }
}

# Query similar cases
query_embedding = openai.embeddings.create(
    model="text-embedding-3-large",
    input="Patient with bleeding gums and tooth pain"
)

results = index.query(
    vector=query_embedding.data[0].embedding,
    filter={
        "tenantId": {"$eq": "tenant_abc"},
        "age": {"$gte": 40, "$lte": 50}
    },
    top_k=10,
    include_metadata=True
)

# Use results for RAG (Retrieval Augmented Generation)
context = "\n\n".join([r.metadata["diagnosis"] for r in results])
prompt = f"Based on similar cases:\n{context}\n\nSuggest treatment for: {patient_symptoms}"
```

### Caching Strategy (Redis)

```typescript
// Multi-layer caching

// L1: Application Memory Cache (LRU)
const memCache = new LRUCache({ max: 1000, ttl: 60000 })

// L2: Redis Cache (Distributed)
const redis = new Redis.Cluster([...nodes])

// L3: Database (MongoDB)

// Cache-aside pattern
async function getPatient(id: string) {
  // L1: Check memory
  let patient = memCache.get(id)
  if (patient) return patient

  // L2: Check Redis
  patient = await redis.get(`patient:${id}`)
  if (patient) {
    memCache.set(id, patient)
    return JSON.parse(patient)
  }

  // L3: Query database
  patient = await db.patients.findOne({ _id: id })
  if (patient) {
    await redis.setex(`patient:${id}`, 300, JSON.stringify(patient))
    memCache.set(id, patient)
  }

  return patient
}

// Cache invalidation on updates
async function updatePatient(id: string, data: any) {
  await db.patients.updateOne({ _id: id }, { $set: data })

  // Invalidate all cache layers
  memCache.delete(id)
  await redis.del(`patient:${id}`)

  // Publish cache invalidation event
  await redis.publish('cache:invalidate', JSON.stringify({ type: 'patient', id }))
}
```

### Event Sourcing (Audit Trail)

```typescript
// Event Store (MongoDB)
{
  _id: ObjectId,
  aggregateId: ObjectId,  // Patient ID
  aggregateType: "patient",
  eventType: "patient_updated" | "treatment_added" | "image_uploaded",
  eventData: {
    before: object,
    after: object,
    changes: string[]
  },
  metadata: {
    userId: ObjectId,
    ipAddress: string,
    userAgent: string,
    timestamp: Date
  },
  version: number  // Event version for ordering
}

// Replay events to rebuild state
async function rebuildPatientState(patientId: string, upToVersion?: number) {
  const events = await db.events.find({
    aggregateId: patientId,
    ...(upToVersion && { version: { $lte: upToVersion } })
  }).sort({ version: 1 })

  let state = {}
  for (const event of events) {
    state = applyEvent(state, event)
  }

  return state
}
```

---

## üîÑ Architecture Streaming & Temps R√©el

### WebSocket Architecture (Socket.io)

```typescript
// Backend: websocket-server.ts
import { Server } from 'socket.io'
import { RedisAdapter } from '@socket.io/redis-adapter'

const io = new Server(httpServer, {
  cors: { origin: process.env.FRONTEND_URL },
  adapter: RedisAdapter  // Multi-server support
})

// Namespace per tenant for isolation
io.of(/^\/tenant-\w+$/).on('connection', async (socket) => {
  const tenantId = socket.nsp.name.replace('/tenant-', '')

  // Authenticate
  const user = await authenticateSocket(socket.handshake.auth.token)
  if (!user || user.tenantId !== tenantId) {
    socket.disconnect()
    return
  }

  // Join tenant room
  socket.join(`tenant:${tenantId}`)

  // Join personal room
  socket.join(`user:${user.id}`)

  // Subscribe to patient updates
  socket.on('subscribe:patient', (patientId) => {
    if (hasPermission(user, 'read', 'patient', patientId)) {
      socket.join(`patient:${patientId}`)
    }
  })

  // Real-time collaboration on dental chart
  socket.on('dentalChart:update', async (data) => {
    // Save to DB
    await db.patients.updateOne(
      { _id: data.patientId },
      { $set: { [`dentalHistory.currentStatus.teeth.${data.toothNumber}`]: data.status } }
    )

    // Broadcast to all users viewing this patient
    socket.to(`patient:${data.patientId}`).emit('dentalChart:updated', {
      toothNumber: data.toothNumber,
      status: data.status,
      updatedBy: user.id,
      timestamp: Date.now()
    })
  })

  // AI transcription streaming
  socket.on('ai:startTranscription', async (sessionId) => {
    const stream = transcriptionStreams.get(sessionId)

    stream.on('chunk', (text) => {
      socket.emit('ai:transcriptionChunk', { text, sessionId })
    })

    stream.on('complete', (fullText) => {
      socket.emit('ai:transcriptionComplete', { fullText, sessionId })
    })
  })
})

// Kafka consumer for broadcasting events
kafka.consumer.on('message', (message) => {
  const event = JSON.parse(message.value)

  // Broadcast to relevant rooms
  io.of(`/tenant-${event.tenantId}`)
    .to(`patient:${event.patientId}`)
    .emit(event.type, event.data)
})
```

### Server-Sent Events (SSE)

```typescript
// Backend: sse-controller.ts
app.get('/api/ai/stream/:sessionId', async (req, res) => {
  const { sessionId } = req.params

  res.writeHead(200, {
    'Content-Type': 'text/event-stream',
    'Cache-Control': 'no-cache',
    'Connection': 'keep-alive',
    'X-Accel-Buffering': 'no'  // Nginx buffering off
  })

  // Subscribe to Kafka topic
  const consumer = kafka.consumer({ groupId: `sse-${sessionId}` })
  await consumer.subscribe({ topic: `ai-stream-${sessionId}` })

  await consumer.run({
    eachMessage: async ({ message }) => {
      const data = JSON.parse(message.value.toString())

      // Send SSE event
      res.write(`data: ${JSON.stringify(data)}\n\n`)
    }
  })

  // Cleanup on client disconnect
  req.on('close', async () => {
    await consumer.disconnect()
    res.end()
  })
})
```

### Kafka Event Streaming

```yaml
Topics:
  patient-events:
    partitions: 12
    replication: 3
    retention: 7 days
    consumers:
      - analytics-service
      - notification-service
      - audit-service

  ai-transcription-stream:
    partitions: 6
    replication: 3
    retention: 1 hour
    consumers:
      - frontend-sse-gateway
      - transcription-archive

  dental-chart-updates:
    partitions: 12
    replication: 3
    retention: 30 days
    consumers:
      - websocket-gateway
      - audit-service
      - analytics-service

Producers:
  - patient-service
  - ai-service
  - dental-chart-service
  - imaging-service

Consumer Groups:
  - real-time (low latency)
  - analytics (batch processing)
  - audit (all events)
```

---

## üìà Architecture Scalabilit√©

### Horizontal Scaling

```yaml
Auto-Scaling Configuration:

API Services (ECS/EKS):
  min_instances: 3
  max_instances: 50
  target_cpu: 70%
  target_memory: 80%
  scale_up_cooldown: 60s
  scale_down_cooldown: 300s

AI Service:
  min_instances: 5
  max_instances: 100
  target_cpu: 80%
  gpu_instances: true (Tesla T4)
  queue_depth_threshold: 100

WebSocket Service:
  min_instances: 3
  max_instances: 20
  connections_per_instance: 5000
  sticky_sessions: true

Database:
  MongoDB:
    shards: 3
    replica_set_per_shard: 3
    max_shards: 12

  Redis:
    cluster_nodes: 6
    replicas_per_node: 2
    max_memory_policy: allkeys-lru

  PostgreSQL:
    read_replicas: 3
    max_connections: 1000
    connection_pooling: PgBouncer (10,000 pool)
```

### Load Balancing Strategy

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   CloudFlare (DDoS Protection + CDN)    ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   AWS Application Load Balancer (ALB)   ‚îÇ
‚îÇ   ‚îú‚îÄ Health Checks (every 5s)          ‚îÇ
‚îÇ   ‚îú‚îÄ SSL Termination                   ‚îÇ
‚îÇ   ‚îú‚îÄ Sticky Sessions (WebSocket)       ‚îÇ
‚îÇ   ‚îî‚îÄ Request Routing                   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                   ‚îÇ
      ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
      ‚îÇ            ‚îÇ            ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ API Pod  ‚îÇ ‚îÇ API Pod  ‚îÇ ‚îÇ API Pod  ‚îÇ
‚îÇ   #1     ‚îÇ ‚îÇ   #2     ‚îÇ ‚îÇ   #3     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Load Balancing Algorithms:
‚îú‚îÄ API Services: Round Robin
‚îú‚îÄ WebSocket: Sticky Session (based on user ID)
‚îú‚îÄ AI Services: Least Connections
‚îî‚îÄ Read Queries: Weighted Round Robin (replicas)
```

### Database Sharding Strategy

```typescript
// MongoDB Sharding (Tenant-based)

// Shard Key: { tenantId: 1, _id: 1 }
// - tenantId ensures tenant isolation
// - _id ensures uniqueness

// Shard Distribution:
// Shard 1: tenantId hash 0x00000000 - 0x55555555
// Shard 2: tenantId hash 0x55555556 - 0xAAAAAAAA
// Shard 3: tenantId hash 0xAAAAAAAAAB - 0xFFFFFFFF

// Query Routing:
// With tenantId ‚Üí Single shard (fast)
db.patients.find({ tenantId: "abc123", lastName: "Smith" })
// Routed to shard containing "abc123"

// Without tenantId ‚Üí Scatter-gather (slow, avoid!)
db.patients.find({ lastName: "Smith" })
// Queries all shards, merges results

// Best Practices:
// 1. Always include tenantId in queries
// 2. Pre-split chunks for even distribution
// 3. Monitor shard balance monthly
// 4. Use compound indexes with tenantId prefix
```

### Caching & CDN Strategy

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ              Client Browser                       ‚îÇ
‚îÇ  ‚îú‚îÄ Service Worker (offline cache)              ‚îÇ
‚îÇ  ‚îî‚îÄ IndexedDB (local patient data)              ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ         CloudFront CDN (Edge Locations)          ‚îÇ
‚îÇ  ‚îú‚îÄ Static Assets (JS, CSS, Images)             ‚îÇ
‚îÇ  ‚îú‚îÄ Medical Images (X-rays, 3D scans)           ‚îÇ
‚îÇ  ‚îú‚îÄ TTL: 1 year (immutable assets)              ‚îÇ
‚îÇ  ‚îî‚îÄ Cache-Control headers                       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           Redis Cluster (L1 Cache)               ‚îÇ
‚îÇ  ‚îú‚îÄ Hot data (frequently accessed)              ‚îÇ
‚îÇ  ‚îú‚îÄ TTL: 5 minutes - 1 hour                     ‚îÇ
‚îÇ  ‚îú‚îÄ Pub/Sub for cache invalidation              ‚îÇ
‚îÇ  ‚îî‚îÄ 100GB RAM per node                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                    ‚îÇ
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚ñº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        MongoDB (Primary Database)                ‚îÇ
‚îÇ  ‚îî‚îÄ Persistent storage                          ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

Cache Layers:
1. Browser (Service Worker): 24h - 1 year
2. CDN (CloudFront): 1 hour - 1 year
3. Redis (Distributed): 5 min - 1 hour
4. MongoDB: Source of truth
```

### Rate Limiting

```typescript
// Multi-layer rate limiting

// 1. CloudFlare (DDoS protection)
// - 1000 req/min per IP
// - Automatic challenge for suspicious traffic

// 2. API Gateway (Kong)
import rateLimit from 'express-rate-limit'

const apiLimiter = rateLimit({
  windowMs: 60 * 1000, // 1 minute
  max: async (req) => {
    const user = req.user

    // Different limits per plan
    switch (user.plan) {
      case 'starter': return 100
      case 'professional': return 500
      case 'enterprise': return 2000
      default: return 60  // Free tier
    }
  },
  standardHeaders: true,
  legacyHeaders: false,
  store: new RedisStore({
    client: redis,
    prefix: 'rl:'
  })
})

// 3. AI Service (Token-based)
const aiLimiter = {
  starter: { tokens: 10000, period: 'month' },
  professional: { tokens: 100000, period: 'month' },
  enterprise: { tokens: -1 }  // unlimited
}

// 4. WebSocket (Connection limit)
const wsLimiter = {
  maxConnectionsPerUser: 5,
  maxMessagesPerSecond: 10,
  banDuration: 300  // 5 minutes if exceeded
}
```

---

## üîí S√©curit√© & Conformit√©

### Authentification & Autorisation

```typescript
// Auth Architecture

// 1. OAuth 2.0 + OpenID Connect (OIDC)
// 2. JWT (Access Token + Refresh Token)
// 3. RBAC (Role-Based Access Control)

// JWT Structure
{
  // Header
  "alg": "RS256",
  "typ": "JWT",

  // Payload
  "sub": "user_123",
  "tenantId": "tenant_abc",
  "role": "dentist",
  "permissions": ["patient:read", "patient:write", "treatment:write"],
  "plan": "professional",
  "iat": 1700000000,
  "exp": 1700003600,  // 1 hour

  // Signature (RS256)
}

// Roles & Permissions
const roles = {
  admin: {
    permissions: ["*:*"]  // All permissions
  },
  dentist: {
    permissions: [
      "patient:*",
      "treatment:*",
      "prescription:*",
      "imaging:*",
      "ai:*",
      "billing:read"
    ]
  },
  assistant: {
    permissions: [
      "patient:read",
      "patient:write",
      "imaging:read",
      "imaging:upload",
      "agenda:*"
    ]
  },
  receptionist: {
    permissions: [
      "patient:read",
      "agenda:*",
      "billing:*"
    ]
  }
}

// Permission Check Middleware
const requirePermission = (resource: string, action: string) => {
  return async (req, res, next) => {
    const user = req.user

    // Check if user has permission
    if (!hasPermission(user.permissions, resource, action)) {
      return res.status(403).json({ error: 'Forbidden' })
    }

    // Check tenant isolation
    if (req.params.tenantId && req.params.tenantId !== user.tenantId) {
      return res.status(403).json({ error: 'Access denied' })
    }

    next()
  }
}

// Usage
app.get('/patients/:id',
  authenticate,
  requirePermission('patient', 'read'),
  getPatient
)
```

### Encryption

```yaml
Encryption at Rest:
  MongoDB:
    - Field-level encryption (sensitive fields)
    - Storage engine: WiredTiger with encryption
    - Keys: AWS KMS (rotation every 90 days)

  S3:
    - SSE-KMS (Server-Side Encryption with KMS)
    - Bucket policy: enforce encryption
    - Keys: AWS KMS (automatic rotation)

  PostgreSQL:
    - Transparent Data Encryption (TDE)
    - Backup encryption
    - Keys: AWS KMS

Encryption in Transit:
  - TLS 1.3 (minimum TLS 1.2)
  - Strong ciphers only (AES-256-GCM)
  - Certificate pinning (mobile apps)
  - mTLS for service-to-service

Encryption in Application:
  - Sensitive fields (NationalRegister, InsuranceNumber)
  - AES-256-GCM
  - Unique IV per record
  - Key management: HashiCorp Vault
```

### RGPD / GDPR Compliance

```typescript
// GDPR Implementation

// 1. Consent Management
interface Consent {
  userId: string
  consentType: 'marketing' | 'analytics' | 'medical'
  granted: boolean
  timestamp: Date
  ipAddress: string
  version: string  // Consent policy version
}

// 2. Right to Access (Data Export)
async function exportUserData(userId: string) {
  const patient = await db.patients.findOne({ _id: userId })
  const images = await db.images.find({ patientId: userId })
  const prescriptions = await db.prescriptions.find({ patientId: userId })
  const invoices = await db.invoices.find({ patientId: userId })

  // Generate PDF/ZIP with all data
  return {
    personalInfo: patient.personalInfo,
    medicalInfo: patient.medicalInfo,
    dentalHistory: patient.dentalHistory,
    images: images.map(i => i.cdnUrl),
    prescriptions,
    invoices,
    exportDate: new Date(),
    format: 'JSON'
  }
}

// 3. Right to Erasure (Delete)
async function deleteUserData(userId: string) {
  // Soft delete (for legal retention)
  await db.patients.updateOne(
    { _id: userId },
    {
      $set: {
        deleted: true,
        deletedAt: new Date(),
        'personalInfo.firstName': '[DELETED]',
        'personalInfo.lastName': '[DELETED]',
        'personalInfo.email': `deleted_${userId}@deleted.com`,
        'personalInfo.phone': '[DELETED]'
      }
    }
  )

  // Anonymize in event logs
  await db.events.updateMany(
    { 'metadata.userId': userId },
    { $set: { 'metadata.userId': 'ANONYMIZED' } }
  )

  // Schedule hard delete after retention period (7 years)
  await scheduleJob({
    type: 'hard_delete_user',
    userId,
    executeAt: addYears(new Date(), 7)
  })
}

// 4. Data Breach Notification (within 72h)
async function notifyDataBreach(breach: DataBreach) {
  // Notify DPA (Data Protection Authority)
  await notifyDPA(breach)

  // Notify affected users
  const affectedUsers = await getAffectedUsers(breach)
  for (const user of affectedUsers) {
    await sendEmail(user.email, 'data_breach', {
      breachType: breach.type,
      dataAffected: breach.dataTypes,
      actionTaken: breach.mitigationSteps
    })
  }

  // Log notification
  await db.breaches.insertOne({
    ...breach,
    notifiedAt: new Date(),
    notifiedUsers: affectedUsers.length
  })
}

// 5. Audit Logging (all data access)
async function logDataAccess(access: DataAccess) {
  await db.auditLogs.insertOne({
    userId: access.userId,
    resource: access.resource,
    action: access.action,
    timestamp: new Date(),
    ipAddress: access.ipAddress,
    userAgent: access.userAgent,
    dataAccessed: access.fields,
    justification: access.reason
  })
}
```

### Belgian Healthcare Compliance (INAMI/e-Health)

```typescript
// INAMI Integration

// 1. eID Authentication (Belgian eID)
import { verifyEID } from 'beid-middleware'

async function authenticateWithEID(cardData: Buffer) {
  const certificate = await verifyEID(cardData)

  // Verify with INAMI registry
  const practitioner = await inami.verifyPractitioner(certificate.nationalNumber)

  if (!practitioner.active) {
    throw new Error('Practitioner not registered with INAMI')
  }

  return {
    userId: practitioner.id,
    nationalNumber: practitioner.nationalNumber,
    specialization: practitioner.specialization,
    inamiNumber: practitioner.inamiNumber
  }
}

// 2. Recip-e Prescription (e-Health)
import { RecipeClient } from '@ehealth/recipe'

async function createRecipePrescription(prescription: Prescription) {
  const recipeClient = new RecipeClient({
    endpoint: 'https://services.recipe.be',
    certificate: await getCertificate(),
    key: await getPrivateKey()
  })

  // Create prescription in Recip-e system
  const recipe = await recipeClient.createPrescription({
    patientSSIN: prescription.patientSSIN,
    practitionerNIHII: prescription.practitionerNIHII,
    medications: prescription.medications.map(med => ({
      code: med.cnkCode,  // Belgian CNK code
      quantity: med.quantity,
      dosage: med.dosage,
      duration: med.duration
    })),
    validUntil: addDays(new Date(), 90)
  })

  // Generate QR code
  const qrCode = await generateQRCode(recipe.prescriptionId)

  // Send to patient (email/SMS)
  await sendPrescription(prescription.patientId, {
    prescriptionId: recipe.prescriptionId,
    qrCode,
    deliveryUrl: recipe.deliveryUrl
  })

  return recipe
}

// 3. MyCareNet (Attestation √©lectronique)
import { MyCareNetClient } from '@mycarenet/sdk'

async function sendAttestation(attestation: Attestation) {
  const mcnClient = new MyCareNetClient({
    endpoint: 'https://mycarenet.be',
    certificate: await getCertificate()
  })

  // Send attestation to insurance
  const response = await mcnClient.sendAttestation({
    practitionerNIHII: attestation.practitionerNIHII,
    patientSSIN: attestation.patientSSIN,
    prestationCode: attestation.prestationCode,
    date: attestation.date,
    amount: attestation.amount,
    insurance: attestation.insurance
  })

  // Store response
  await db.attestations.updateOne(
    { _id: attestation._id },
    {
      $set: {
        status: response.accepted ? 'accepted' : 'rejected',
        myCareNetResponse: response,
        processedAt: new Date()
      }
    }
  )

  return response
}
```

---

## üìä Monitoring & Observabilit√©

### Metrics Collection

```typescript
// Prometheus Metrics

import { register, Counter, Histogram, Gauge } from 'prom-client'

// HTTP Requests
const httpRequestDuration = new Histogram({
  name: 'http_request_duration_seconds',
  help: 'HTTP request duration in seconds',
  labelNames: ['method', 'route', 'status_code']
})

const httpRequestTotal = new Counter({
  name: 'http_requests_total',
  help: 'Total HTTP requests',
  labelNames: ['method', 'route', 'status_code']
})

// AI Requests
const aiRequestDuration = new Histogram({
  name: 'ai_request_duration_seconds',
  help: 'AI request duration in seconds',
  labelNames: ['model', 'task_type']
})

const aiRequestCost = new Counter({
  name: 'ai_request_cost_dollars',
  help: 'AI request cost in dollars',
  labelNames: ['model', 'tenant_id']
})

// Database Queries
const dbQueryDuration = new Histogram({
  name: 'db_query_duration_seconds',
  help: 'Database query duration in seconds',
  labelNames: ['collection', 'operation']
})

// WebSocket Connections
const wsConnections = new Gauge({
  name: 'websocket_connections',
  help: 'Active WebSocket connections',
  labelNames: ['tenant_id']
})

// Middleware to track metrics
app.use((req, res, next) => {
  const start = Date.now()

  res.on('finish', () => {
    const duration = (Date.now() - start) / 1000

    httpRequestDuration.labels(req.method, req.route?.path, res.statusCode).observe(duration)
    httpRequestTotal.labels(req.method, req.route?.path, res.statusCode).inc()
  })

  next()
})
```

### Distributed Tracing (Jaeger)

```typescript
// OpenTelemetry + Jaeger

import { NodeTracerProvider } from '@opentelemetry/sdk-trace-node'
import { JaegerExporter } from '@opentelemetry/exporter-jaeger'
import { registerInstrumentations } from '@opentelemetry/instrumentation'
import { HttpInstrumentation } from '@opentelemetry/instrumentation-http'
import { MongoDBInstrumentation } from '@opentelemetry/instrumentation-mongodb'

const provider = new NodeTracerProvider()

provider.addSpanProcessor(
  new BatchSpanProcessor(
    new JaegerExporter({
      endpoint: 'http://jaeger:14268/api/traces'
    })
  )
)

provider.register()

registerInstrumentations({
  instrumentations: [
    new HttpInstrumentation(),
    new MongoDBInstrumentation(),
    new RedisInstrumentation()
  ]
})

// Custom span
const tracer = provider.getTracer('dental-api')

async function getPatient(id: string) {
  const span = tracer.startSpan('getPatient')
  span.setAttribute('patient.id', id)

  try {
    const patient = await db.patients.findOne({ _id: id })
    span.setAttribute('patient.found', !!patient)
    return patient
  } catch (error) {
    span.recordException(error)
    throw error
  } finally {
    span.end()
  }
}
```

### Alerting (Prometheus Alertmanager)

```yaml
# Alerting Rules

groups:
  - name: api_alerts
    interval: 30s
    rules:
      # High Error Rate
      - alert: HighErrorRate
        expr: |
          rate(http_requests_total{status_code=~"5.."}[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value }} (threshold: 0.05)"

      # Slow Response Time
      - alert: SlowResponseTime
        expr: |
          histogram_quantile(0.95, http_request_duration_seconds) > 1
        for: 10m
        labels:
          severity: warning
        annotations:
          summary: "Slow response time detected"
          description: "P95 latency is {{ $value }}s (threshold: 1s)"

      # Database Connection Pool Exhausted
      - alert: DBConnectionPoolExhausted
        expr: |
          mongodb_connections_current >= mongodb_connections_max * 0.9
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "DB connection pool nearly exhausted"

      # High AI Cost
      - alert: HighAICost
        expr: |
          rate(ai_request_cost_dollars[1h]) > 100
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High AI costs detected"
          description: "AI cost is ${{ $value }}/hour"

      # WebSocket Connections Limit
      - alert: HighWebSocketConnections
        expr: |
          websocket_connections > 8000
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High WebSocket connection count"

  - name: infrastructure_alerts
    interval: 30s
    rules:
      # High CPU
      - alert: HighCPUUsage
        expr: |
          avg by (instance) (rate(container_cpu_usage_seconds_total[5m])) > 0.8
        for: 10m
        labels:
          severity: warning

      # High Memory
      - alert: HighMemoryUsage
        expr: |
          container_memory_usage_bytes / container_spec_memory_limit_bytes > 0.9
        for: 5m
        labels:
          severity: critical

      # Disk Space Low
      - alert: DiskSpaceLow
        expr: |
          (node_filesystem_avail_bytes / node_filesystem_size_bytes) < 0.1
        for: 5m
        labels:
          severity: critical
```

### Logging (Loki + Grafana)

```typescript
// Structured Logging

import pino from 'pino'

const logger = pino({
  level: process.env.LOG_LEVEL || 'info',
  transport: {
    target: 'pino-loki',
    options: {
      host: 'http://loki:3100',
      labels: {
        app: 'dentalcockpit',
        environment: process.env.NODE_ENV
      }
    }
  }
})

// Log with context
logger.info({
  userId: '123',
  tenantId: 'abc',
  action: 'patient_updated',
  patientId: '456',
  duration: 150
}, 'Patient record updated')

// Error logging
try {
  await updatePatient(id, data)
} catch (error) {
  logger.error({
    err: error,
    userId: req.user.id,
    patientId: id
  }, 'Failed to update patient')
}

// Performance logging
const start = Date.now()
const result = await expensiveOperation()
logger.info({
  operation: 'expensive_operation',
  duration: Date.now() - start
}, 'Operation completed')
```

---

## üöÄ D√©ploiement & Infrastructure

### Kubernetes Configuration

```yaml
# kubernetes/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: api-service
  namespace: dentalcockpit
spec:
  replicas: 3
  selector:
    matchLabels:
      app: api-service
  template:
    metadata:
      labels:
        app: api-service
    spec:
      containers:
      - name: api
        image: dentalcockpit/api:latest
        ports:
        - containerPort: 3000
        env:
        - name: NODE_ENV
          value: "production"
        - name: MONGODB_URI
          valueFrom:
            secretKeyRef:
              name: db-secrets
              key: mongodb-uri
        - name: REDIS_URI
          valueFrom:
            secretKeyRef:
              name: cache-secrets
              key: redis-uri
        resources:
          requests:
            memory: "512Mi"
            cpu: "500m"
          limits:
            memory: "1Gi"
            cpu: "1000m"
        livenessProbe:
          httpGet:
            path: /health
            port: 3000
          initialDelaySeconds: 30
          periodSeconds: 10
        readinessProbe:
          httpGet:
            path: /ready
            port: 3000
          initialDelaySeconds: 5
          periodSeconds: 5

---

apiVersion: v1
kind: Service
metadata:
  name: api-service
  namespace: dentalcockpit
spec:
  selector:
    app: api-service
  ports:
  - protocol: TCP
    port: 80
    targetPort: 3000
  type: ClusterIP

---

apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: api-service-hpa
  namespace: dentalcockpit
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: api-service
  minReplicas: 3
  maxReplicas: 50
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
  - type: Resource
    resource:
      name: memory
      target:
        type: Utilization
        averageUtilization: 80
```

### CI/CD Pipeline (GitHub Actions)

```yaml
# .github/workflows/deploy.yml

name: Deploy to Production

on:
  push:
    branches: [main]

jobs:
  test:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Setup Node.js
        uses: actions/setup-node@v3
        with:
          node-version: '20'

      - name: Install dependencies
        run: npm ci

      - name: Run tests
        run: npm test

      - name: Run E2E tests
        run: npm run test:e2e

  build:
    needs: test
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3

      - name: Build Docker image
        run: docker build -t dentalcockpit/api:${{ github.sha }} .

      - name: Push to ECR
        run: |
          aws ecr get-login-password | docker login --username AWS --password-stdin ${{ secrets.ECR_REGISTRY }}
          docker tag dentalcockpit/api:${{ github.sha }} ${{ secrets.ECR_REGISTRY }}/api:${{ github.sha }}
          docker push ${{ secrets.ECR_REGISTRY }}/api:${{ github.sha }}

  deploy:
    needs: build
    runs-on: ubuntu-latest
    steps:
      - name: Deploy to EKS
        run: |
          aws eks update-kubeconfig --name dentalcockpit-prod
          kubectl set image deployment/api-service api=${{ secrets.ECR_REGISTRY }}/api:${{ github.sha }}
          kubectl rollout status deployment/api-service

      - name: Verify deployment
        run: |
          kubectl get pods -l app=api-service
          kubectl logs -l app=api-service --tail=100
```

### Infrastructure as Code (Terraform)

```hcl
# terraform/main.tf

# EKS Cluster
resource "aws_eks_cluster" "dentalcockpit" {
  name     = "dentalcockpit-prod"
  role_arn = aws_iam_role.eks_cluster.arn
  version  = "1.28"

  vpc_config {
    subnet_ids              = aws_subnet.private[*].id
    endpoint_private_access = true
    endpoint_public_access  = true
  }
}

# Node Group
resource "aws_eks_node_group" "dentalcockpit" {
  cluster_name    = aws_eks_cluster.dentalcockpit.name
  node_group_name = "dentalcockpit-nodes"
  node_role_arn   = aws_iam_role.eks_nodes.arn
  subnet_ids      = aws_subnet.private[*].id

  scaling_config {
    desired_size = 3
    max_size     = 50
    min_size     = 3
  }

  instance_types = ["t3.large"]
}

# MongoDB Atlas
resource "mongodbatlas_cluster" "dentalcockpit" {
  project_id = var.mongodb_project_id
  name       = "dentalcockpit-prod"

  provider_name               = "AWS"
  provider_region_name        = "EU_WEST_1"
  provider_instance_size_name = "M30"

  cluster_type = "SHARDED"
  num_shards   = 3

  replication_specs {
    num_shards = 3
    regions_config {
      region_name     = "EU_WEST_1"
      electable_nodes = 3
      priority        = 7
      read_only_nodes = 0
    }
  }

  backup_enabled = true
  auto_scaling_disk_gb_enabled = true
}

# Redis Cluster (ElastiCache)
resource "aws_elasticache_replication_group" "dentalcockpit" {
  replication_group_id       = "dentalcockpit-redis"
  replication_group_description = "Redis cluster for DentalCockpit"
  engine                     = "redis"
  engine_version             = "7.0"
  node_type                  = "cache.r6g.xlarge"
  number_cache_clusters      = 6
  automatic_failover_enabled = true
  multi_az_enabled           = true

  at_rest_encryption_enabled = true
  transit_encryption_enabled = true
  auth_token                 = var.redis_auth_token
}

# S3 Bucket (Images)
resource "aws_s3_bucket" "medical_images" {
  bucket = "dentalcockpit-medical-images"

  versioning {
    enabled = true
  }

  server_side_encryption_configuration {
    rule {
      apply_server_side_encryption_by_default {
        sse_algorithm     = "aws:kms"
        kms_master_key_id = aws_kms_key.s3.arn
      }
    }
  }

  lifecycle_rule {
    enabled = true

    transition {
      days          = 90
      storage_class = "STANDARD_IA"
    }

    transition {
      days          = 365
      storage_class = "GLACIER"
    }
  }
}
```

---

## üìÖ Plan de D√©veloppement

### Phase 1: MVP (3 mois)

```
Mois 1: Infrastructure & Core Services
‚îú‚îÄ Semaine 1-2: Setup infrastructure (K8s, MongoDB, Redis)
‚îú‚îÄ Semaine 3-4: Auth service + Patient service
‚îî‚îÄ Deliverables:
    ‚îú‚îÄ Infrastructure as Code (Terraform)
    ‚îú‚îÄ CI/CD pipeline
    ‚îú‚îÄ Auth system (JWT, RBAC)
    ‚îî‚îÄ Patient CRUD API

Mois 2: Frontend & Core Features
‚îú‚îÄ Semaine 1-2: Next.js setup + UI components
‚îú‚îÄ Semaine 3-4: Dental chart + Patient management
‚îî‚îÄ Deliverables:
    ‚îú‚îÄ Landing page (4 langues)
    ‚îú‚îÄ Dashboard layout
    ‚îú‚îÄ Dental charting interface
    ‚îî‚îÄ Patient list + details

Mois 3: AI Integration
‚îú‚îÄ Semaine 1-2: RCE engine + Whisper transcription
‚îú‚îÄ Semaine 3-4: GPT-4 anamnesis + Testing
‚îî‚îÄ Deliverables:
    ‚îú‚îÄ Voice recording + transcription
    ‚îú‚îÄ AI anamnesis generation
    ‚îú‚îÄ RCE orchestration layer
    ‚îî‚îÄ MVP ready for beta testing
```

### Phase 2: Advanced Features (3 mois)

```
Mois 4: Imaging & AI Analysis
‚îú‚îÄ Image upload (X-ray, 3D scans)
‚îú‚îÄ DICOM support
‚îú‚îÄ Gemini vision analysis
‚îî‚îÄ Annotations & measurements

Mois 5: Prescriptions & Billing
‚îú‚îÄ Prescription creation
‚îú‚îÄ Recip-e integration (Belgian e-Health)
‚îú‚îÄ INAMI integration
‚îî‚îÄ Stripe payments

Mois 6: Analytics & Reports
‚îú‚îÄ Dashboard KPIs
‚îú‚îÄ AI predictions (revenue, no-shows)
‚îú‚îÄ Custom reports
‚îî‚îÄ Data export (GDPR)
```

### Phase 3: Scale & Optimize (3 mois)

```
Mois 7: Performance & Scalability
‚îú‚îÄ Load testing (10K+ concurrent users)
‚îú‚îÄ Database sharding
‚îú‚îÄ CDN optimization
‚îî‚îÄ Caching strategy refinement

Mois 8: Security & Compliance
‚îú‚îÄ Penetration testing
‚îú‚îÄ GDPR audit
‚îú‚îÄ INAMI certification
‚îî‚îÄ SOC 2 compliance

Mois 9: Polish & Launch
‚îú‚îÄ Mobile apps (React Native)
‚îú‚îÄ Advanced AI features
‚îú‚îÄ Multi-tenant management
‚îî‚îÄ Production launch üöÄ
```

---

## üéØ Technologies Stack Summary

```
Frontend:
‚îú‚îÄ Next.js 14+ (React 18+, TypeScript 5+)
‚îú‚îÄ Zustand + TanStack Query + RxJS
‚îú‚îÄ Tailwind CSS + Radix UI + Framer Motion
‚îú‚îÄ Socket.io + SSE + WebRTC
‚îî‚îÄ D3.js + Three.js

Backend:
‚îú‚îÄ Node.js 20+ / Bun 1.0+
‚îú‚îÄ Fastify + tRPC + GraphQL
‚îú‚îÄ MongoDB 7+ (sharded) + Redis 7+ (cluster)
‚îú‚îÄ Pinecone/Weaviate (vectors)
‚îú‚îÄ Kafka + BullMQ
‚îî‚îÄ PostgreSQL 16+ (audit)

AI:
‚îú‚îÄ RCE Engine (custom orchestrator)
‚îú‚îÄ OpenAI (GPT-4, Whisper)
‚îú‚îÄ Anthropic (Claude 3.5 Sonnet)
‚îú‚îÄ Google (Gemini Pro 1.5)
‚îî‚îÄ LangChain + FAISS

Infrastructure:
‚îú‚îÄ AWS EKS (Kubernetes 1.28+)
‚îú‚îÄ CloudFront + S3
‚îú‚îÄ Istio (service mesh)
‚îú‚îÄ Terraform (IaC)
‚îî‚îÄ GitHub Actions (CI/CD)

Monitoring:
‚îú‚îÄ Datadog / New Relic (APM)
‚îú‚îÄ Prometheus + Grafana
‚îú‚îÄ Loki (logs)
‚îú‚îÄ Jaeger (tracing)
‚îî‚îÄ Sentry (errors)
```

---

**Auteur:** Ismail Sialyen
**Powered by:** RCE (Relational Cognitive Engine)
**Version:** 2.0
**Date:** 12/11/2025
